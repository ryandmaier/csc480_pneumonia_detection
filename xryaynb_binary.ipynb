{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4696 578 582\n",
      "1282 3414\n",
      "155 427\n",
      "146 432\n"
     ]
    }
   ],
   "source": [
    "from cgi import test\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "base_dir = 'chest_xray/'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_NORMAL_dir = os.path.join(train_dir, 'NORMAL')\n",
    "train_PNEUMONIA_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
    "\n",
    "validation_NORMAL_dir = os.path.join(validation_dir, 'NORMAL')\n",
    "validation_PNEUMONIA_dir = os.path.join(validation_dir, 'PNEUMONIA')\n",
    "\n",
    "test_NORMAL_dir = os.path.join(test_dir, 'NORMAL')\n",
    "test_PNEUMONIA_dir = os.path.join(test_dir, 'PNEUMONIA')\n",
    "\n",
    "train_NORMAL_fnames = os.listdir(train_NORMAL_dir)\n",
    "train_PNEUMONIA_fnames = os.listdir(train_PNEUMONIA_dir)\n",
    "\n",
    "validation_NORMAL_fnames = os.listdir(validation_NORMAL_dir)\n",
    "validation_PNEUMONIA_fnames = os.listdir(validation_PNEUMONIA_dir)\n",
    "\n",
    "test_NORMAL_fnames = os.listdir(test_NORMAL_dir)\n",
    "test_PNEUMONIA_fnames = os.listdir(test_PNEUMONIA_dir)\n",
    "\n",
    "n_train = len(train_NORMAL_fnames) + len(train_PNEUMONIA_fnames)\n",
    "n_validation = len(validation_NORMAL_fnames) + len(validation_PNEUMONIA_fnames)\n",
    "n_test = len(test_NORMAL_fnames) + len(test_PNEUMONIA_fnames)\n",
    "\n",
    "print(n_train, n_validation, n_test)\n",
    "print(len(train_NORMAL_fnames),len(train_PNEUMONIA_fnames))\n",
    "print(len(test_NORMAL_fnames),len(test_PNEUMONIA_fnames))\n",
    "print(len(validation_NORMAL_fnames),len(validation_PNEUMONIA_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4696 images belonging to 2 classes.\n",
      "Found 578 images belonging to 2 classes.\n",
      "Found 582 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                   samplewise_center=True,\n",
    "                                   samplewise_std_normalization=True,\n",
    "                                   zoom_range = 0.2, \n",
    "                                   width_shift_range=0.1,  \n",
    "                                   height_shift_range=0.1)\n",
    "\n",
    "validation_datagen  = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                         samplewise_center=True,\n",
    "                                         samplewise_std_normalization=True,\n",
    "                                         zoom_range = 0.2, \n",
    "                                         width_shift_range=0.1,  \n",
    "                                         height_shift_range=0.1)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1.0/255,\n",
    "                                    samplewise_center=True,\n",
    "                                    samplewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=16,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(160, 160))\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              batch_size=16,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(160, 160))\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  class_mode='binary',\n",
    "                                                  target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "293/293 [==============================] - 370s 1s/step - loss: 0.3362 - accuracy: 0.8628 - precision: 0.8947 - recall: 0.9195 - val_loss: 0.4897 - val_accuracy: 0.7803 - val_precision: 0.7738 - val_recall: 0.9977\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 330s 1s/step - loss: 0.2204 - accuracy: 0.9113 - precision: 0.9325 - recall: 0.9465 - val_loss: 0.1623 - val_accuracy: 0.9377 - val_precision: 0.9381 - val_recall: 0.9815\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 328s 1s/step - loss: 0.1886 - accuracy: 0.9265 - precision: 0.9455 - recall: 0.9538 - val_loss: 0.1729 - val_accuracy: 0.9273 - val_precision: 0.9333 - val_recall: 0.9722\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 328s 1s/step - loss: 0.1868 - accuracy: 0.9274 - precision: 0.9469 - recall: 0.9536 - val_loss: 0.3389 - val_accuracy: 0.8287 - val_precision: 0.9826 - val_recall: 0.7847\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 323s 1s/step - loss: 0.1762 - accuracy: 0.9346 - precision: 0.9529 - recall: 0.9574 - val_loss: 0.1410 - val_accuracy: 0.9481 - val_precision: 0.9718 - val_recall: 0.9583\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 334s 1s/step - loss: 0.1594 - accuracy: 0.9385 - precision: 0.9561 - recall: 0.9594 - val_loss: 0.1707 - val_accuracy: 0.9325 - val_precision: 0.9804 - val_recall: 0.9282\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 335s 1s/step - loss: 0.1511 - accuracy: 0.9400 - precision: 0.9580 - recall: 0.9594 - val_loss: 0.1297 - val_accuracy: 0.9446 - val_precision: 0.9484 - val_recall: 0.9792\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 332s 1s/step - loss: 0.1527 - accuracy: 0.9419 - precision: 0.9562 - recall: 0.9641 - val_loss: 0.1138 - val_accuracy: 0.9671 - val_precision: 0.9769 - val_recall: 0.9792\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 325s 1s/step - loss: 0.1456 - accuracy: 0.9459 - precision: 0.9600 - recall: 0.9659 - val_loss: 0.3158 - val_accuracy: 0.8685 - val_precision: 0.9972 - val_recall: 0.8264\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 326s 1s/step - loss: 0.1369 - accuracy: 0.9485 - precision: 0.9637 - recall: 0.9656 - val_loss: 0.0896 - val_accuracy: 0.9706 - val_precision: 0.9859 - val_recall: 0.9745\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 323s 1s/step - loss: 0.1313 - accuracy: 0.9494 - precision: 0.9647 - recall: 0.9656 - val_loss: 0.2189 - val_accuracy: 0.9100 - val_precision: 0.9974 - val_recall: 0.8819\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 319s 1s/step - loss: 0.1353 - accuracy: 0.9494 - precision: 0.9631 - recall: 0.9674 - val_loss: 0.1368 - val_accuracy: 0.9516 - val_precision: 0.9787 - val_recall: 0.9560\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 323s 1s/step - loss: 0.1216 - accuracy: 0.9532 - precision: 0.9652 - recall: 0.9706 - val_loss: 0.1292 - val_accuracy: 0.9533 - val_precision: 0.9903 - val_recall: 0.9468\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 319s 1s/step - loss: 0.1322 - accuracy: 0.9498 - precision: 0.9623 - recall: 0.9688 - val_loss: 0.1633 - val_accuracy: 0.9498 - val_precision: 0.9927 - val_recall: 0.9398\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 342s 1s/step - loss: 0.1228 - accuracy: 0.9588 - precision: 0.9690 - recall: 0.9744 - val_loss: 0.1861 - val_accuracy: 0.9273 - val_precision: 0.9974 - val_recall: 0.9051\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 2917s 10s/step - loss: 0.1179 - accuracy: 0.9568 - precision: 0.9700 - recall: 0.9706 - val_loss: 0.0993 - val_accuracy: 0.9654 - val_precision: 0.9747 - val_recall: 0.9792\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 200s 683ms/step - loss: 0.1211 - accuracy: 0.9541 - precision: 0.9669 - recall: 0.9700 - val_loss: 0.0872 - val_accuracy: 0.9758 - val_precision: 0.9860 - val_recall: 0.9815\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 185s 631ms/step - loss: 0.1190 - accuracy: 0.9564 - precision: 0.9678 - recall: 0.9724 - val_loss: 0.0956 - val_accuracy: 0.9706 - val_precision: 0.9748 - val_recall: 0.9861\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 185s 629ms/step - loss: 0.1092 - accuracy: 0.9585 - precision: 0.9712 - recall: 0.9718 - val_loss: 0.1020 - val_accuracy: 0.9654 - val_precision: 0.9791 - val_recall: 0.9745\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 1130s 4s/step - loss: 0.1134 - accuracy: 0.9571 - precision: 0.9700 - recall: 0.9709 - val_loss: 0.1257 - val_accuracy: 0.9498 - val_precision: 0.9903 - val_recall: 0.9421\n",
      "Model: \"X-ray_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 158, 158, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 158, 158, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 158, 158, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 79, 79, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 77, 77, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 77, 77, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 77, 77, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 38, 38, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 36, 36, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 36, 36, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 36, 36, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 18, 18, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,437,569\n",
      "Trainable params: 4,436,865\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential(name='X-ray_CNN')\n",
    "\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(160,160,3)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu')) # relu activation makes each value 0 if it is negative\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "METRICS = ['accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=METRICS)\n",
    "history = model.fit(train_generator, \n",
    "          steps_per_epoch= n_train//16,\n",
    "          validation_data=validation_generator,\n",
    "          epochs=20,\n",
    "          verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: xraymodel_binary_20221130_131741\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: xraymodel_binary_20221130_131741\\assets\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "model.save('xraymodel_binary_'+str(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion(n, generator, title, batch_size):\n",
    "    labels = []\n",
    "    for i in range(0, n//batch_size):\n",
    "        # print(i)\n",
    "        labels.extend(generator[i][1])\n",
    "    labels = np.array(labels)\n",
    "    print(len(labels))\n",
    "    # preds = model.predict_classes(generator)\n",
    "    preds = (model.predict(generator) > 0.5).astype(\"int32\")\n",
    "    preds = np.reshape(preds, n)\n",
    "\n",
    "    cm  = confusion_matrix(labels, preds[:len(labels)])\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=False,cmap=plt.cm.Blues)\n",
    "    plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "    plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "    plt.title(title, fontsize=20)\n",
    "    return plt.show()\n",
    "\n",
    "plot_confusion(n_test, test_generator, 'Test set', 32)\n",
    "plot_confusion(n_train, train_generator, 'Training set', 16)\n",
    "plot_confusion(n_validation, validation_generator, 'Validation set', 16)\n",
    "\n",
    "# 0.973958 accuracy for test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc7e758b011b8546c2d8d6136d2d13627abe8c022b73c6b30824a33af506f0a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
